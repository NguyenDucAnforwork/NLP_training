{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenDucAnforwork/NLP_training/blob/main/Copy_of_HAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This dataset is fetched from:\n",
        "https://www.kaggle.com/datasets/jarupula/yahoo-answers-dataset\n",
        "\n",
        "## I use pretrained model Glove for vector embeddings with 50 dimensions"
      ],
      "metadata": {
        "id": "pjb6thKmlarz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"using device {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhXZeAWdQ6Pz",
        "outputId": "48147462-98d0-4bbd-ccbc-650e03fd0261"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwpIMQk02m5_",
        "outputId": "990e0da9-f0ab-47b9-ec1d-2dfca66651cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.6B.50d.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/  test.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exhzNDTq3wc_",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title install necessary libraries\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M5WHVqrA323g",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title import libraries + declaring necessary parameters\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import re, nltk\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import nltk\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from bs4 import BeautifulSoup\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read data + pretrained model\n"
      ],
      "metadata": {
        "id": "uwzlt-PfE2Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert word to vector embedding from pretrained model\n",
        "file_path = './glove.6B.200d.txt'\n",
        "\n",
        "vocab = {}\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "\n",
        "        vector = torch.tensor([float(val) if val != '-' else 0 for val in parts[1:]])\n",
        "        vocab[word] = vector"
      ],
      "metadata": {
        "id": "Fq-gTWv_IQcT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(datapath):\n",
        "    documents, labels = [], []\n",
        "    with open(datapath, encoding='latin-1') as csv_file:\n",
        "        reader = csv.reader(csv_file, quotechar='\"')\n",
        "        for idx, line in enumerate(reader):\n",
        "            if (line[0] == \"\"):\n",
        "                break\n",
        "            text = \"\"\n",
        "            for tx in line[1:]:\n",
        "                feature_cleaned = tx.replace('\"', '').replace('\\\\n', ' ').replace('\\\\', ' ').replace(',', ' ')\n",
        "                text += feature_cleaned.lower()\n",
        "                text += \" \"\n",
        "            label = int(line[0]) - 1\n",
        "\n",
        "            if text:\n",
        "                documents.append(text)\n",
        "            labels.append(label)\n",
        "    return documents, labels\n",
        "\n",
        "X_train, y_train = read_data(\"./train.csv\")\n",
        "X_test, y_test = read_data(\"./test.csv\")\n",
        "\n",
        "train_docs, train_labels = X_train[:7680], y_train[:7680]\n",
        "valid_docs, valid_labels = X_train[7680:9600], y_train[7680:9600]\n",
        "test_docs, test_labels = X_test[:992], y_test[:992]"
      ],
      "metadata": {
        "id": "poRX7Ql3YU_L"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter = Counter(train_labels)\n",
        "most_common = counter.most_common(2)\n",
        "print(most_common)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8LlO2ZvLDVM",
        "outputId": "897c45ee-12cd-4b7d-bda3-aedf8978ec3b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6, 1896), (4, 1102)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing"
      ],
      "metadata": {
        "id": "-Y-IwapRE9I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title remove unwanted characters\n",
        "nltk.download('punkt')\n",
        "\n",
        "def split_into_sentences(document):\n",
        "    document = re.sub(r\"[\\[\\]']\", \"\", document)\n",
        "    sentences = re.split(r\"[.!?,]\", document)\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "def preprocess(document):\n",
        "    sentences = split_into_sentences(document)\n",
        "    sentence_embeddings = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence_embedding = []\n",
        "        for word in sentence:\n",
        "            if word in vocab:\n",
        "                word_embedding = torch.tensor(vocab[word]).float()  # Load embedding from Glove model\n",
        "            else:\n",
        "                word_embedding = torch.randn(200)\n",
        "            sentence_embedding.append(word_embedding)   # (sent_len, embed_size)\n",
        "\n",
        "        if sentence_embedding:  # Check if sentence_embedding is not empty\n",
        "            sentence_embeddings.append(torch.stack(sentence_embedding)) # (doc_len, sent_max_len, embed_size)\n",
        "\n",
        "    if sentence_embeddings:  # Check if sentence_embeddings is not empty\n",
        "        padded_document = pad_sequence(sentence_embeddings, batch_first=True).to(device)\n",
        "    else:\n",
        "        padded_document = torch.tensor([]).to(device)  # Empty tensor if no valid sentences\n",
        "    return padded_document\n",
        "\n",
        "# Assuming train_docs, valid_docs, and test_docs are already defined\n",
        "train_documents = [preprocess(document) for document in train_docs]\n",
        "valid_documents = [preprocess(document) for document in valid_docs]\n",
        "test_documents = [preprocess(document) for document in test_docs]\n",
        "\n",
        "# Now your documents are on the GPU\n",
        "print(\"Train document tensor shapes:\", [doc.shape for doc in train_documents])\n",
        "print(\"Validation document tensor shapes:\", [doc.shape for doc in valid_documents])\n",
        "print(\"Test document tensor shapes:\", [doc.shape for doc in test_documents])\n"
      ],
      "metadata": {
        "id": "Af9TmnOs3h7Q",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "a6bd6e05-fdb4-4d4b-b27a-154532eaf340",
        "cellView": "form"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "<ipython-input-57-f7865a1179f7>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  word_embedding = torch.tensor(vocab[word]).float()  # Load embedding from Glove model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-f7865a1179f7>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Assuming train_docs, valid_docs, and test_docs are already defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mvalid_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtest_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-f7865a1179f7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Assuming train_docs, valid_docs, and test_docs are already defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mvalid_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtest_documents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_docs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-f7865a1179f7>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(document)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence_embeddings\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if sentence_embeddings is not empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpadded_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpadded_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Empty tensor if no valid sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title padding + truncating\n",
        "max_num_sent = config['max_num_sent']\n",
        "max_sent_len = config['max_sent_len']\n",
        "embed_size = config['embed_dim']\n",
        "\n",
        "def padding(documents):\n",
        "    max_num_sent = config['max_num_sent']\n",
        "    max_sent_len = config['max_sent_len']\n",
        "    embed_size = config['embed_dim']\n",
        "    for i, doc in enumerate(documents):\n",
        "        num_sent, sent_len, _ = doc.size()\n",
        "        pad_num_sent = max_num_sent - num_sent\n",
        "        pad_sent_len = max_sent_len - sent_len\n",
        "\n",
        "        if pad_num_sent > 0:\n",
        "            pad = torch.zeros(pad_num_sent, sent_len, embed_size).to(device)\n",
        "            documents[i] = torch.cat([doc, pad], dim=0)\n",
        "\n",
        "        else:\n",
        "            documents[i] = documents[i][:max_num_sent, :, :]\n",
        "        if pad_sent_len > 0:\n",
        "            pad = torch.zeros(max_num_sent, pad_sent_len, embed_size).to(device)\n",
        "            documents[i] = torch.cat([documents[i], pad], dim=1)\n",
        "        else:\n",
        "            documents[i] = documents[i][:, :max_sent_len, :]\n",
        "    return documents\n",
        "\n",
        "train_documents = padding(train_documents)\n",
        "valid_documents = padding(valid_documents)\n",
        "test_documents = padding(test_documents)"
      ],
      "metadata": {
        "id": "9U7P9OqgbxIr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_documents[0].size())"
      ],
      "metadata": {
        "id": "Y05EIuBRm8Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset + dataloader\n",
        "- size of a batch of data: (batch_size, max_doc_len, max_sent_len, embed_size) [16, 8, 64, 50]\n"
      ],
      "metadata": {
        "id": "N8j5jOGnFDIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, documents, labels):\n",
        "        self.documents = [doc.to(device) for doc in documents]  # Move documents to GPU\n",
        "        self.labels = [torch.tensor(label).to(device) for label in labels]    # Convert labels to tensors and move to GPU\n",
        "        self.embed_size = 50\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= 0 and idx < len(self.documents):\n",
        "            return {'idx': idx, 'document': self.documents[idx], 'label': self.labels[idx]}   # (num_sent, max_sent_len, embed_size)\n",
        "\n",
        "# Assuming train_documents, train_labels, valid_documents, valid_labels, test_documents, and test_labels are already defined\n",
        "train_dataset = TextDataset(train_documents, train_labels)\n",
        "test_dataset = TextDataset(test_documents, test_labels)\n",
        "valid_dataset = TextDataset(valid_documents, valid_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "DffOqNG7dS-5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    sample_batch, sample_label = batch['document'], batch['label']\n",
        "    print(sample_batch.size(), sample_label.size())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EgPCaLNqlkT",
        "outputId": "14232f74-e050-48e6-bfd0-0610ff22b682",
        "collapsed": true
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 30, 200]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_batch[:, 0, :, :].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNWiWNZYSkwE",
        "outputId": "363253c5-dcc5-4e63-9b92-5f8563f06339"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 30, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title configuration\n",
        "config = {\n",
        "    \"max_num_sent\" : 8,\n",
        "    \"max_sent_len\" : 30,\n",
        "    \"embed_dim\" : 200,\n",
        "    \"batch_size\" : 32,\n",
        "    \"context_size1\" : 100,\n",
        "    \"context_size2\" : 100,\n",
        "    \"hidden_size1\" : 50,\n",
        "    \"hidden_size2\" : 50,\n",
        "    \"num_class\" : 10\n",
        "}"
      ],
      "metadata": {
        "id": "jwzFjP1GUNtw",
        "cellView": "form"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model architecture + model summary\n"
      ],
      "metadata": {
        "id": "_40eDp4NFKMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordEncoder(nn.Module): # (batch_size, max_sent_len, embed_dim)\n",
        "    def __init__(self, embed_dim=config['embed_dim'], hidden_size1=config['hidden_size1'], batch_size=config['batch_size']):\n",
        "        super(WordEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_size1 = hidden_size1\n",
        "        self.gru = nn.GRU(embed_dim, hidden_size1, bidirectional=True, batch_first=True)\n",
        "        self.h_0 = nn.Parameter(torch.zeros(2, batch_size, hidden_size1))\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.gru.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):   # hidden state = [2, batch_size, hidden_size1] cuz it's bidirectional\n",
        "        outputs, h_n = self.gru(inputs, self.h_0)\n",
        "        return outputs   # (batch_size, max_sent_len, 2 * hidden_size1)"
      ],
      "metadata": {
        "id": "dh1CHcSmFX32"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = WordEncoder()\n",
        "out1 = a(sample_batch[:, 0, :, :])\n",
        "print(out1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so0CkLfbRuGL",
        "outputId": "3be37abb-a78e-4b5c-b6fd-60f79b1041fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 30, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WordAttention(nn.Module):   # input_size = 2 * sent_hidden_size   |   sent_hidden_size = context_size\n",
        "    def __init__(self, input_size=2*config['hidden_size1'], context_size1=config['context_size1']):\n",
        "        super(WordAttention, self).__init__()\n",
        "        self.context_size1 = context_size1\n",
        "        self.score_weight_matrix = nn.Linear(input_size, context_size1, bias=True)\n",
        "        self.context_vector = nn.Parameter(torch.randn(context_size1, 1))\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "    def forward(self, output_tensors):   # (batch_size, max_sent_length, 2*sent_hidden_size). notations are little bit confusing\n",
        "        u_i = torch.tanh(self.score_weight_matrix(output_tensors))   #  (batch_size, max_sent_length, context_size)\n",
        "        dot_product = torch.matmul(u_i, self.context_vector)  # (batch_size, max_sent_len)\n",
        "        a_i = nn.Softmax(dim=1)(dot_product)  # (batch_size, max_sent_len, 1)\n",
        "        s_i = (a_i * output_tensors).sum(dim=1)  # (batch_size, input_size)\n",
        "        return s_i"
      ],
      "metadata": {
        "id": "4PW_yFnLFKbf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = WordAttention()\n",
        "out2 = b(out1)\n",
        "print(out2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IvfIfcUTBsr",
        "outputId": "f2c5b78b-48e2-4bfe-e8bf-cc18e6393f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceEncoder(nn.Module):\n",
        "    def __init__(self, input_size=2*config['hidden_size1'], hidden_size2=config['hidden_size2']):  # (batch_size, max_doc_len, context_size1)\n",
        "        super(SentenceEncoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.gru = nn.GRU(input_size, hidden_size2, bidirectional=True, batch_first=True)   # (batch_size, max_doc_len, (2 * hidden_size2))\n",
        "        self.h_0 = nn.Parameter(torch.zeros(2, config['batch_size'], hidden_size2))\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs, h_n = self.gru(inputs, self.h_0)\n",
        "        return outputs   # (batch_size, max_doc_len, 2 * hidden_size2)"
      ],
      "metadata": {
        "id": "RieLja0RV3Ud"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for i in range(sample_batch.shape[1]):\n",
        "    doc = sample_batch[:, i, :, :]\n",
        "    out1 = a(doc)\n",
        "    out2 = b(out1)\n",
        "    outputs.append(out2)\n",
        "outputs = torch.stack(outputs).transpose(0,1)\n",
        "print(outputs.shape)\n",
        "c = SentenceEncoder()\n",
        "out3 = c(outputs)\n",
        "print(out3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5vb17zZZJqf",
        "outputId": "895f009b-a671-41e7-873c-f7ee0908f2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 8, 100])\n",
            "torch.Size([32, 8, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceAttention(nn.Module):\n",
        "    def __init__(self, input_size=2*config['hidden_size2'], context_size2=config['context_size2']):\n",
        "        super(SentenceAttention, self).__init__()\n",
        "        self.context_size2 = context_size2\n",
        "        self.score_weight_matrix = nn.Linear(input_size, context_size2, bias=True)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.context_vector = nn.Parameter(torch.randn(context_size2, 1))\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "    def forward(self, encoded_sent):   # (batch_size, max_doc_len, input_size)\n",
        "        u_i = torch.tanh(self.score_weight_matrix(encoded_sent))   # (batch_size, max_doc_len, hidden_size)\n",
        "        dot_product = torch.matmul(u_i, self.context_vector)  # (batch_size, max_doc_len)\n",
        "        a_i = nn.Softmax(dim=1)(dot_product)  # (batch_size, max_doc_len)\n",
        "        s_i = (a_i * encoded_sent).sum(dim=1) # (batch_size, input_size)\n",
        "        return s_i"
      ],
      "metadata": {
        "id": "HE40xP2KV9aG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = SentenceAttention()\n",
        "out4 = d(out3)\n",
        "print(out4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXNCXGDkgeTS",
        "outputId": "ee418a4e-be2f-498c-e81e-4d51a3b9032f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(han())"
      ],
      "metadata": {
        "id": "lK617vnlCA5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentClassification(nn.Module):   # (batch_size, 2 * doc_hidden_units)\n",
        "    def __init__(self, input_size=2*config['hidden_size2'], num_class=config['num_class']):\n",
        "        super(DocumentClassification, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_class, bias=True)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "    def forward(self, encoded_doc):\n",
        "      p = self.linear(encoded_doc)   # (batch_size, num_class)\n",
        "      p = nn.Softmax(dim=1)(p)\n",
        "      return p"
      ],
      "metadata": {
        "id": "yPrHEDXJWAWJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(out4.shape)\n",
        "e = DocumentClassification()\n",
        "out5 = e(out4)\n",
        "print(out5.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F_krNj2JiucX",
        "outputId": "c14c765e-2910-407f-f754-e60006a04f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100])\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HAN(nn.Module):\n",
        "    def __init__(self, embed_dim=config['embed_dim'], hidden_size1=config['hidden_size1'], hidden_size2=config['hidden_size2'], context_size1=config['context_size1'], context_size2=config['context_size2'], num_class=config['num_class']):\n",
        "        super(HAN, self).__init__()\n",
        "        self.word_encoder = WordEncoder(embed_dim, hidden_size1)\n",
        "        self.word_att = WordAttention(2 * hidden_size1, context_size1)\n",
        "        self.sentence_encoder = SentenceEncoder(2 * hidden_size1, hidden_size2)\n",
        "        self.sentence_att = SentenceAttention(2 * hidden_size2, context_size2)\n",
        "        self.doc_classify = DocumentClassification(2 * hidden_size2, num_class)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.normal_(param.data, mean=0.0, std=0.05)\n",
        "\n",
        "    def forward(self, inputs):   # (batch_size, max_doc_len, max_sent_len, embed_size)\n",
        "        document_embedding = []   # (max_doc_len, batch_size, 2 * hidden_size1)\n",
        "        for i in range(inputs.shape[1]):\n",
        "            sentences = inputs[:, i, :, :]\n",
        "            out1 = self.word_encoder(sentences)   # (batch_size, max_sent_len, 2 * hidden_size1)\n",
        "            out2 = self.word_att(out1)   # (batch_size, 2 * hidden_size1)\n",
        "            document_embedding.append(out2.clone())\n",
        "        document_embedding = torch.stack(document_embedding).transpose(0, 1)   # (batch_size, max_doc_len, 2 * hidden_size1)\n",
        "        encoded_document = self.sentence_encoder(document_embedding)\n",
        "        out = self.sentence_att(encoded_document)\n",
        "        predictions = self.doc_classify(out)\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "dNGhz9-cWD7d"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "han = HAN()\n",
        "print(han(sample_batch).shape)"
      ],
      "metadata": {
        "id": "Mjw-Hl4ma5NS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6339832e-dce4-4c67-d378-f5413a06edb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title print out all learnable parameters\n",
        "def print_learnable_parameters(model):\n",
        "    print(\"Learnable parameters in the model:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        param.requires_grad=True\n",
        "        if param.requires_grad:\n",
        "            print(f\"{name}: {param.shape}\")\n",
        "        if param.grad is None:\n",
        "            print(f\"No gradient for {name}\")\n",
        "\n",
        "# Print learnable parameters\n",
        "print_learnable_parameters(han)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "7Kk7bo3MB4Bq",
        "outputId": "d64225ac-2fb0-464c-9bad-de058fe0eb47"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learnable parameters in the model:\n",
            "word_encoder.h_0: torch.Size([2, 32, 50])\n",
            "word_encoder.gru.weight_ih_l0: torch.Size([150, 200])\n",
            "word_encoder.gru.weight_hh_l0: torch.Size([150, 50])\n",
            "word_encoder.gru.bias_ih_l0: torch.Size([150])\n",
            "word_encoder.gru.bias_hh_l0: torch.Size([150])\n",
            "word_encoder.gru.weight_ih_l0_reverse: torch.Size([150, 200])\n",
            "word_encoder.gru.weight_hh_l0_reverse: torch.Size([150, 50])\n",
            "word_encoder.gru.bias_ih_l0_reverse: torch.Size([150])\n",
            "word_encoder.gru.bias_hh_l0_reverse: torch.Size([150])\n",
            "word_att.context_vector: torch.Size([100, 1])\n",
            "word_att.score_weight_matrix.weight: torch.Size([100, 100])\n",
            "word_att.score_weight_matrix.bias: torch.Size([100])\n",
            "sentence_encoder.h_0: torch.Size([2, 32, 50])\n",
            "sentence_encoder.gru.weight_ih_l0: torch.Size([150, 100])\n",
            "sentence_encoder.gru.weight_hh_l0: torch.Size([150, 50])\n",
            "sentence_encoder.gru.bias_ih_l0: torch.Size([150])\n",
            "sentence_encoder.gru.bias_hh_l0: torch.Size([150])\n",
            "sentence_encoder.gru.weight_ih_l0_reverse: torch.Size([150, 100])\n",
            "sentence_encoder.gru.weight_hh_l0_reverse: torch.Size([150, 50])\n",
            "sentence_encoder.gru.bias_ih_l0_reverse: torch.Size([150])\n",
            "sentence_encoder.gru.bias_hh_l0_reverse: torch.Size([150])\n",
            "sentence_att.context_vector: torch.Size([100, 1])\n",
            "sentence_att.score_weight_matrix.weight: torch.Size([100, 100])\n",
            "sentence_att.score_weight_matrix.bias: torch.Size([100])\n",
            "doc_classify.linear.weight: torch.Size([10, 100])\n",
            "doc_classify.linear.bias: torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title change the way model's weights are initialized\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "han.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "l8ZNMU_zC3iA",
        "outputId": "ed31aab9-c26d-478f-a092-345c0f4c249f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HAN(\n",
              "  (word_encoder): WordEncoder(\n",
              "    (gru): GRU(200, 50, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (word_att): WordAttention(\n",
              "    (score_weight_matrix): Linear(in_features=100, out_features=100, bias=True)\n",
              "  )\n",
              "  (sentence_encoder): SentenceEncoder(\n",
              "    (gru): GRU(100, 50, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (sentence_att): SentenceAttention(\n",
              "    (score_weight_matrix): Linear(in_features=100, out_features=100, bias=True)\n",
              "    (softmax): Softmax(dim=1)\n",
              "  )\n",
              "  (doc_classify): DocumentClassification(\n",
              "    (linear): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate class weights\n",
        "class_counts = np.bincount(train_labels)\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "class_weights = class_weights.to(device)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9Xb2-MqQFjj3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training loop\n"
      ],
      "metadata": {
        "id": "F43tKrXbFHBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# han = HAN().to(device)\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load('checkpoint.pth')\n",
        "\n",
        "# Initialize model\n",
        "han.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Assuming HAN model and train_loader are already defined\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(han.parameters(), lr=2e-3, momentum=0.8)\n",
        "\n",
        "num_epochs = 30\n",
        "previous_epoch_loss = float('inf')\n",
        "epoch_losses, validation_losses = [], []\n",
        "\n",
        "han.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for batch in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
        "            optimizer.zero_grad()\n",
        "            documents, labels = batch['document'].to(device), batch['label'].to(device)\n",
        "            outputs = han(documents)\n",
        "            encoded_labels = []\n",
        "            for label in labels:\n",
        "                ex = torch.zeros(10)\n",
        "                ex[int(label) - 1] = 1\n",
        "                encoded_labels.append(ex)\n",
        "            stacked_labels = torch.stack(encoded_labels).to(device)\n",
        "            loss = criterion(outputs, stacked_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    epoch_losses.append(average_loss)\n",
        "    print(f'Training loss: {average_loss}')\n",
        "\n",
        "    # han.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            documents, labels = batch['document'].to(device), batch['label'].to(device)\n",
        "            outputs = han(documents)\n",
        "            encoded_labels = []\n",
        "            for label in labels:\n",
        "                ex = torch.zeros(10)\n",
        "                ex[int(label) - 1] = 1\n",
        "                encoded_labels.append(ex)\n",
        "            stacked_labels = torch.stack(encoded_labels).to(device)\n",
        "            loss = criterion(outputs, stacked_labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    average_val_loss = total_val_loss / len(valid_loader)\n",
        "    validation_losses.append(average_val_loss)\n",
        "    print(f'Validation loss: {average_val_loss}')\n",
        "\n",
        "    torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': han.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': previous_epoch_loss,\n",
        "    }, 'checkpoint.pth')\n",
        "\n",
        "    # if abs(previous_epoch_loss - average_loss) < 1e-5:\n",
        "    #     print(f'Stopping early at epoch {epoch+1} due to small loss change')\n",
        "    #     break\n",
        "\n",
        "    previous_epoch_loss = average_loss\n",
        "\n",
        "# Plotting the loss function\n",
        "plt.plot(epoch_losses, label='Training Loss')\n",
        "plt.plot(validation_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Sr0C0WkYSoGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "659bcc20-0fa6-4a8e-dd25-de30529e3dd7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 240/240 [00:06<00:00, 39.83batch/s, loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.214276291926702\n",
            "Validation loss: 2.1991730610529583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  71%|███████   | 170/240 [00:04<00:01, 36.44batch/s, loss=2.34]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-e73275fe6779>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-91a3cef0dac5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (batch_size, max_sent_len, 2 * hidden_size1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_att\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (batch_size, 2 * hidden_size1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mdocument_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdocument_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (batch_size, max_doc_len, 2 * hidden_size1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f884ff58d84a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_tensors)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# (batch_size, max_sent_length, 2*sent_hidden_size). notations are little bit confusing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mu_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_weight_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#  (batch_size, max_sent_length, context_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, max_sent_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0ma_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_product\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, max_sent_len, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0ms_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title print the content of checkpoint.pth\n",
        "import torch\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load('checkpoint.pth')\n",
        "\n",
        "# Print the keys in the checkpoint\n",
        "# print(\"Keys in checkpoint:\")\n",
        "# for key in checkpoint.keys():\n",
        "#     print(f\"{key}: {checkpoint[key]}\")\n",
        "\n",
        "# If you want to inspect the content of the model state dictionary\n",
        "print(\"\\nModel state dict:\")\n",
        "for name, param in checkpoint['model_state_dict'].items():\n",
        "    print(f\"{name}: {param.shape}\")\n",
        "\n",
        "# If you want to inspect the optimizer state dictionary\n",
        "# print(\"\\nOptimizer state dict:\")\n",
        "# for name, param in checkpoint['optimizer_state_dict'].items():\n",
        "#     print(f\"{name}: {param}\")\n",
        "\n",
        "# Print other items if needed\n",
        "if 'epoch' in checkpoint:\n",
        "    print(f\"\\nEpoch: {checkpoint['epoch']}\")\n",
        "if 'loss' in checkpoint:\n",
        "    print(f\"Loss: {checkpoint['loss']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "nbAdGAFAGovG",
        "outputId": "bc98bffd-3e73-4c6b-c951-f4ea993d7c20"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model state dict:\n",
            "word_encoder.h_0: torch.Size([2, 32, 50])\n",
            "word_encoder.gru.weight_ih_l0: torch.Size([150, 200])\n",
            "word_encoder.gru.weight_hh_l0: torch.Size([150, 50])\n",
            "word_encoder.gru.bias_ih_l0: torch.Size([150])\n",
            "word_encoder.gru.bias_hh_l0: torch.Size([150])\n",
            "word_encoder.gru.weight_ih_l0_reverse: torch.Size([150, 200])\n",
            "word_encoder.gru.weight_hh_l0_reverse: torch.Size([150, 50])\n",
            "word_encoder.gru.bias_ih_l0_reverse: torch.Size([150])\n",
            "word_encoder.gru.bias_hh_l0_reverse: torch.Size([150])\n",
            "word_att.context_vector: torch.Size([100, 1])\n",
            "word_att.score_weight_matrix.weight: torch.Size([100, 100])\n",
            "word_att.score_weight_matrix.bias: torch.Size([100])\n",
            "sentence_encoder.h_0: torch.Size([2, 32, 50])\n",
            "sentence_encoder.gru.weight_ih_l0: torch.Size([150, 100])\n",
            "sentence_encoder.gru.weight_hh_l0: torch.Size([150, 50])\n",
            "sentence_encoder.gru.bias_ih_l0: torch.Size([150])\n",
            "sentence_encoder.gru.bias_hh_l0: torch.Size([150])\n",
            "sentence_encoder.gru.weight_ih_l0_reverse: torch.Size([150, 100])\n",
            "sentence_encoder.gru.weight_hh_l0_reverse: torch.Size([150, 50])\n",
            "sentence_encoder.gru.bias_ih_l0_reverse: torch.Size([150])\n",
            "sentence_encoder.gru.bias_hh_l0_reverse: torch.Size([150])\n",
            "sentence_att.context_vector: torch.Size([100, 1])\n",
            "sentence_att.score_weight_matrix.weight: torch.Size([100, 100])\n",
            "sentence_att.score_weight_matrix.bias: torch.Size([100])\n",
            "doc_classify.linear.weight: torch.Size([10, 100])\n",
            "doc_classify.linear.bias: torch.Size([10])\n",
            "\n",
            "Epoch: 100\n",
            "Loss: 0.003569740305344264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "4T-FjbbldV4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load checkpoint\n",
        "checkpoint = torch.load('checkpoint.pth')\n",
        "\n",
        "# Initialize model\n",
        "han.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Evaluation code\n",
        "han.eval()  # Set the model to evaluation mode\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for batch in test_loader:\n",
        "        documents, labels = batch['document'].to(device), batch['label'].to(device)\n",
        "        outputs = han(documents).to(device)\n",
        "\n",
        "        # Get the predicted labels\n",
        "        predicted_labels = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Here you can add code to evaluate the predictions\n",
        "# For example, calculating accuracy or other metrics\n",
        "\n",
        "fixed_all_labels = [int(label)-1 for label in all_labels]\n",
        "accuracy = sum(1 for x, y in zip(all_predictions, fixed_all_labels) if x == y) / len(all_labels)\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "zyqP6YS5dY-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ac0f88-1cfa-4a6d-cea4-f93d250c1f2d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.2651209677419355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len([x for x in all_predictions if x != 5]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxAy4tBsJggA",
        "outputId": "d85b5100-c28a-42a5-912f-90bebf3e6db1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "uwzlt-PfE2Hp",
        "-Y-IwapRE9I7",
        "N8j5jOGnFDIV",
        "_40eDp4NFKMh",
        "F43tKrXbFHBU",
        "4T-FjbbldV4c"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}